# -*- coding: utf-8 -*-
"""two_armed_bandit_problem.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vObp6l6JyKmcbwIpYCLiEukXHT107Lnh
"""

from numpy.core.fromnumeric import argmax
import numpy as np
import math
import matplotlib.pyplot as plt

number_of_slot_machines = 2
conversion_rates = np.random.uniform(0.01, 0.15, number_of_slot_machines)
highest_conversion_rate=max(conversion_rates)
array_for_regret_ucb=[]
array_for_regret_ts=[]

y1=[]
y2=[]

time_array=[10,20,50,100,150,100,200,500,750,1000,2000]
max_cumulative_reward_from_ucb1=0
max_cumulative_reward_from_ts=0
for j in time_array:
    
  #UCB
  cumulative_rewards=[0,0]
  play_counts=[0,0]
  for slot_machine_index in range(number_of_slot_machines):
    play_counts[slot_machine_index]+=1
    if np.random.rand() <= conversion_rates[slot_machine_index]:
      cumulative_rewards[slot_machine_index]+=1
  g=[0,0]
  for t in range(number_of_slot_machines,j):
    for slot_machine_index in range(number_of_slot_machines):
      g[slot_machine_index]=(cumulative_rewards[slot_machine_index]/play_counts[slot_machine_index])+math.sqrt(2*math.log(t,10)/play_counts[slot_machine_index])
    optimistic_selection=np.argmax(g)
    if np.random.rand() <= conversion_rates[optimistic_selection]:
      cumulative_rewards[optimistic_selection]+=1
    play_counts[optimistic_selection]+=1
    array_for_regret_ucb.append(highest_conversion_rate-conversion_rates[optimistic_selection])
  #print('decision of UCB is the machine',np.argmax(cumulative_rewards))



  #TS
  success=[0,0]
  fail=[0,0]
  for t in range(j):
    random_from_beta=[0,0]
    for N in range(number_of_slot_machines):
      random_from_beta[N]=np.random.beta(success[N]+1,fail[N]+1)
    selected_arm=np.argmax(random_from_beta)
    if np.random.rand() <= conversion_rates[selected_arm]:
      success[selected_arm]+=1
    else:
      fail[selected_arm]+=1
    array_for_regret_ts.append(highest_conversion_rate-conversion_rates[selected_arm])
  #print('decision of TS is the machine',np.argmax(success))
  
  y1.append(sum(array_for_regret_ucb))
  y2.append(sum(array_for_regret_ts))

  if j==200:
    max_cumulative_reward_from_ucb1=max(cumulative_rewards)
    max_cumulative_reward_from_ts=max(success)

for i in range(2):
  print('Conversion rate for slot machine {0}: {1:.2%}'.format(i, conversion_rates[i]))

plt.plot(time_array, y2, label = "regret ts")
plt.plot(time_array, y1, label = "regret ucb")
plt.xlabel('x - axis')
plt.ylabel('y - axis')
plt.title('Regrets')
plt.legend()
plt.show()

#UCB-V
def sample_mean_calculator_for_ucb_v(i,j,rewards_for_v_ucb):
  x=0
  for k in range(j):
    x+=rewards_for_v_ucb[i][k]
  x=x/j
  return x
def sample_variance_calculator_for_ucb_v(i,j,rewards_for_v_ucb):
  x=0
  for k in range(j):
    x+=(rewards_for_v_ucb[i][k]-(sample_mean_calculator_for_ucb_v(i,j,rewards_for_v_ucb)))**2
  x=x/j
  return x

rewards_for_v_ucb=[[0 for i in range(200)],[0 for i in range(200)]]
for slot_machine_index in range(number_of_slot_machines):
  if np.random.rand() <= conversion_rates[slot_machine_index]:
    rewards_for_v_ucb[slot_machine_index][0]=1
  else:
    rewards_for_v_ucb[slot_machine_index][0]=0
rewards_for_v_ucb[0][1]=0
rewards_for_v_ucb[1][0]=0
b=[0,0]
number_of_times_arm_selected=[1,1]
for t in range(number_of_slot_machines,200):
  for k in range(number_of_slot_machines):
    b[k]=sample_mean_calculator_for_ucb_v(k,number_of_times_arm_selected[k],rewards_for_v_ucb)+math.sqrt(2*sample_variance_calculator_for_ucb_v(k,number_of_times_arm_selected[k],rewards_for_v_ucb)*2*math.log(t)*(1/number_of_times_arm_selected[k]))+3*math.log(t)*1/number_of_times_arm_selected[k]
  selected_arm=np.argmax(b)
  number_of_times_arm_selected[selected_arm]+=1
  if np.random.rand() <= conversion_rates[selected_arm]:
    rewards_for_v_ucb[selected_arm][t]=1
  else:
    rewards_for_v_ucb[selected_arm][t]=0



#KL-UCB
def determining_sup(k,j,rewards):
  list1=np.linspace(.0, 1.0, num=20)
  list_1=[]
  x=0
  mean=sample_mean_calculator_for_ucb_v(k,j,rewards)
  list_1.append(x)
  for q in list1[1:19]:
    x=math.exp(mean)*(mean/q) + math.exp(1-mean)*(1-mean/1-q)
    list_1.append(x)
  
  return min(list_1)

number_of_times_arm_selected=[1,1]
b=[0,0]
rewards_for_kl_ucb=[[0 for i in range(200)],[0 for i in range(200)]]
for slot_machine_index in range(number_of_slot_machines):
  if np.random.rand() <= conversion_rates[slot_machine_index]:
    rewards_for_kl_ucb[slot_machine_index][0]=1
  else:
    rewards_for_kl_ucb[slot_machine_index][0]=0
rewards_for_kl_ucb[0][1]=0
rewards_for_kl_ucb[1][0]=0
for t in range(number_of_slot_machines,200):
  for k in range(number_of_slot_machines):
    b[k]= number_of_times_arm_selected[k]*determining_sup(k,number_of_times_arm_selected[k],rewards_for_kl_ucb)
  selected_arm=np.argmax(b)
  number_of_times_arm_selected[selected_arm]+=1
  if np.random.rand() <= conversion_rates[selected_arm]:
    rewards_for_kl_ucb[selected_arm][t]=1
  else:
    rewards_for_kl_ucb[selected_arm][t]=0

print("max cumulative rewards from UCB-V at 200 rounds: ", max(sum(rewards_for_v_ucb[0]),sum(rewards_for_v_ucb[1])))
print("max cumulative rewards from TS at 200 rounds: ",max_cumulative_reward_from_ts)
print("max cumulative rewards from UCB1 at 200 rounds: ",max_cumulative_reward_from_ucb1)
print("max cumulative rewards from KL-UCB at 200 rounds: ", max(sum(rewards_for_kl_ucb[0]),sum(rewards_for_kl_ucb[1])))

from numpy.core.fromnumeric import argmax
import numpy as np
import math
import matplotlib.pyplot as plt

def sample_mean_calculator_for_ucb_v(i,j,rewards_for_v_ucb):
  x=0
  for k in range(j):
    x+=rewards_for_v_ucb[i][k]
  x=x/j
  return x
def sample_variance_calculator_for_ucb_v(i,j,rewards_for_v_ucb):
  x=0
  for k in range(j):
    x+=(rewards_for_v_ucb[i][k]-(sample_mean_calculator_for_ucb_v(i,j,rewards_for_v_ucb)))**2
  x=x/j
  return x
def determining_sup(k,j,rewards):
  list1=np.linspace(.0, 1.0, num=20)
  list_1=[]
  x=0
  mean=sample_mean_calculator_for_ucb_v(k,j,rewards)
  list_1.append(x)
  for q in list1[1:19]:
    x=math.exp(mean)*(mean/q) + math.exp(1-mean)*(1-mean/1-q)
    list_1.append(x)
  
  return min(list_1)

number_of_slot_machines = 2
conversion_rates = np.random.uniform(0.01, 0.15, number_of_slot_machines)
highest_conversion_rate=max(conversion_rates)
array_for_regret_ucb=[]
array_for_regret_ts=[]

y1=[]
y2=[]

time_array=[10,20,50,100,150,100,200,300,400,500]
cumulative_reward_from_ucb1=0
cumulative_reward_from_ts=0
cumulative_reward_from_ucbv=0
cumulative_reward_from_ucbkl=0


for j in time_array:

  #KL-UCB
  number_of_times_arm_selected=[1,1]
  b=[0,0]
  rewards_for_kl_ucb=[[0 for i in range(j)],[0 for i in range(j)]]
  for slot_machine_index in range(number_of_slot_machines):
    if np.random.rand() <= conversion_rates[slot_machine_index]:
      rewards_for_kl_ucb[slot_machine_index][0]=1
    else:
      rewards_for_kl_ucb[slot_machine_index][0]=0
  rewards_for_kl_ucb[0][1]=0
  rewards_for_kl_ucb[1][0]=0
  for t in range(number_of_slot_machines,j):
    for k in range(number_of_slot_machines):
      b[k]= number_of_times_arm_selected[k]*determining_sup(k,number_of_times_arm_selected[k],rewards_for_kl_ucb)
    selected_arm=np.argmax(b)
    number_of_times_arm_selected[selected_arm]+=1
    if np.random.rand() <= conversion_rates[selected_arm]:
      rewards_for_kl_ucb[selected_arm][t]=1
    else:
      rewards_for_kl_ucb[selected_arm][t]=0

  #UCB-V
  rewards_for_v_ucb=[[0 for i in range(j)],[0 for i in range(j)]]
  for slot_machine_index in range(number_of_slot_machines):
    if np.random.rand() <= conversion_rates[slot_machine_index]:
      rewards_for_v_ucb[slot_machine_index][0]=1
    else:
      rewards_for_v_ucb[slot_machine_index][0]=0
  rewards_for_v_ucb[0][1]=0
  rewards_for_v_ucb[1][0]=0
  b=[0,0]
  number_of_times_arm_selected=[1,1]
  for t in range(number_of_slot_machines,j):
    for k in range(number_of_slot_machines):
      b[k]=sample_mean_calculator_for_ucb_v(k,number_of_times_arm_selected[k],rewards_for_v_ucb)+math.sqrt(2*sample_variance_calculator_for_ucb_v(k,number_of_times_arm_selected[k],rewards_for_v_ucb)*2*math.log(t)*(1/number_of_times_arm_selected[k]))+3*math.log(t)*1/number_of_times_arm_selected[k]
    selected_arm=np.argmax(b)
    number_of_times_arm_selected[selected_arm]+=1
    if np.random.rand() <= conversion_rates[selected_arm]:
      rewards_for_v_ucb[selected_arm][t]=1
    else:
      rewards_for_v_ucb[selected_arm][t]=0
    
  #UCB1
  cumulative_rewards=[0,0]
  play_counts=[0,0]
  for slot_machine_index in range(number_of_slot_machines):
    play_counts[slot_machine_index]+=1
    if np.random.rand() <= conversion_rates[slot_machine_index]:
      cumulative_rewards[slot_machine_index]+=1
  g=[0,0]
  for t in range(number_of_slot_machines,j):
    for slot_machine_index in range(number_of_slot_machines):
      g[slot_machine_index]=(cumulative_rewards[slot_machine_index]/play_counts[slot_machine_index])+math.sqrt(2*math.log(t,10)/play_counts[slot_machine_index])
    optimistic_selection=np.argmax(g)
    if np.random.rand() <= conversion_rates[optimistic_selection]:
      cumulative_rewards[optimistic_selection]+=1
    play_counts[optimistic_selection]+=1
    array_for_regret_ucb.append(highest_conversion_rate-conversion_rates[optimistic_selection])
  #print('decision of UCB is the machine',np.argmax(cumulative_rewards))



  #TS
  success=[0,0]
  fail=[0,0]
  for t in range(j):
    random_from_beta=[0,0]
    for N in range(number_of_slot_machines):
      random_from_beta[N]=np.random.beta(success[N]+1,fail[N]+1)
    selected_arm=np.argmax(random_from_beta)
    if np.random.rand() <= conversion_rates[selected_arm]:
      success[selected_arm]+=1
    else:
      fail[selected_arm]+=1
    array_for_regret_ts.append(highest_conversion_rate-conversion_rates[selected_arm])
  #print('decision of TS is the machine',np.argmax(success))
  
  y1.append(sum(array_for_regret_ucb))
  y2.append(sum(array_for_regret_ts))

  
  cumulative_reward_from_ucb1+=max(cumulative_rewards)
  cumulative_reward_from_ts+=max(success)
  cumulative_reward_from_ucbv+=max(sum(rewards_for_v_ucb[0]),sum(rewards_for_v_ucb[1]))
  cumulative_reward_from_ucbkl+=max(sum(rewards_for_kl_ucb[0]),sum(rewards_for_kl_ucb[1]))

print("ucb1:",cumulative_reward_from_ucb1)
print("ucbv:",cumulative_reward_from_ucbv)
print("ucbkl:",cumulative_reward_from_ucbkl)
print("ts:",cumulative_reward_from_ts)